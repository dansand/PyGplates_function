{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygplates\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as mplcm\n",
    "from labellines import labelLine, labelLines\n",
    "from create_gpml import create_gpml_regular_long_lat_mesh\n",
    "from skimage import measure\n",
    "import points_in_polygons\n",
    "import csv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetRiftLength(rift_name):\n",
    "    length = [] \n",
    "    for time in range(410,num_of_time_steps+10,10):\n",
    "        rift_length_total = 0.\n",
    "        rift_length = rift.get_geometry().get_arc_length()\n",
    "        individual_rift_length_kms = rift_length * pygplates.Earth.mean_radius_in_kms\n",
    "        tmp_valid_time = np.arange(int(rift.get_valid_time()[1]),\n",
    "                                   int(rift.get_description())+1, 1)\n",
    "        #print rift.get_valid_time()[0] > time\n",
    "        #print int(rift.get_description()) < time\n",
    "        if (rift.get_valid_time()[0] > time) and (int(rift.get_description()) < time):\n",
    "            rift_length_total+=individual_rift_length_kms\n",
    "        length.append(rift_length_total)\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_pip(time,points,polygons,rotation_model):\n",
    "    \n",
    "    reconstructed_polygons = []\n",
    "    pygplates.reconstruct(polygons,rotation_model,reconstructed_polygons,time)\n",
    "    \n",
    "    rpolygons = []\n",
    "    for polygon in reconstructed_polygons:\n",
    "        #print polygon\n",
    "        #if polygon.get_reconstructed_geometry() == 'PolygonOnSphere':\n",
    "        if polygon.get_reconstructed_geometry():\n",
    "            #print polygon.get_reconstructed_geometry()\n",
    "            rpolygons.append(polygon.get_reconstructed_geometry())\n",
    "\n",
    "\n",
    "    polygons_containing_points = points_in_polygons.find_polygons(points, rpolygons)\n",
    "\n",
    "    lat = []\n",
    "    lon = []\n",
    "    zval = []\n",
    "    \n",
    "    for pcp,point in zip(polygons_containing_points,points):\n",
    "        lat.append(point.get_latitude())\n",
    "        lon.append(point.get_longitude())\n",
    "        if pcp is not None:\n",
    "            zval.append(1)\n",
    "        else:\n",
    "            zval.append(0)\n",
    "            \n",
    "    bi = np.array(zval).reshape(181,361)\n",
    "    \n",
    "    return bi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting parameters\n",
    "num_of_time_steps = 1000\n",
    "plotting_times_Mer17GR = np.arange(500,1010,10)\n",
    "plotting_times_Mer17EPSL = np.arange(0,1010,10)\n",
    "plotting_times_Mer17Dom16 = np.arange(410, 1010, 10)\n",
    "plotting_times_DomMerge = np.arange(410,510,10)\n",
    "plotting_times_Mul16 = np.arange(0,250,10)\n",
    "plotting_times_Matt16 = np.arange(0,420,10)\n",
    "linewidth = 3.0\n",
    "markersize = 60\n",
    "axes_title_fontsize = 40\n",
    "tick_fontsize = 30\n",
    "title_fontsize = 70\n",
    "leg_font = 20\n",
    "major_ticks = np.arange(410, 1030, 30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set path to rotation file, shapes etc.\n",
    "basedir = '/Users/Andrew/Documents/PhD/Models/1000-410_Models'\n",
    "basedir2 = '/Users/Andrew/Documents/EarthByte_Models/Matthews++_410-0Ma'\n",
    "basedir3 = '/Users/Andrew/Documents/PhD/Manuscripts'\n",
    "\n",
    "\n",
    "input_rotation_model_1000_500 = '%s/Topos_for_plotting/1000-410_rotations(finished)_20170621a_north_china-tarim-aus.rot' % basedir\n",
    "input_rotation_model_500_410 = '/Users/Andrew/Documents/PhD/Models/Domeier_models/Merge/Domeier-EarlyP-merge-Rotation_ASM.rot'\n",
    "input_rotation_model_410_0 = '/Applications/GPlates-2.0.0/SampleData/FeatureCollections/Rotations/Matthews_etal_GPC_2016_410-0Ma_GK07.rot'\n",
    "\n",
    "input_shapes_1000_500 = '%s/Topos_for_plotting/Neoproterozoic_Palaeozoic_Shapes_20170714_new-antarctica.gpml' % basedir\n",
    "input_shapes_500_410 = '/Users/Andrew/Documents/PhD/Models/Domeier_models/Merge/Domeier-EarlyP-merge-Land_ASM.gpml'\n",
    "input_shapes_410_0 = '%s/StaticGeometries/Coastlines/Global_coastlines_2015_v1_low_res.shp' % basedir2\n",
    "\n",
    "input_COBs_1000_500 = '%s/COBs_global_artificial_individual.gpml' % basedir\n",
    "input_COBs_500_410 = '/Users/Andrew/Documents/PhD/Models/Domeier_models/Merge/Matthews_COBs_for_Dom-models.gpml'\n",
    "input_COBs_410_0 = '%s/StaticGeometries/AgeGridInput/Global_EarthByte_GeeK07_COB_Terranes_Matthews_etal.gpml' % basedir2\n",
    "\n",
    "input_rifts = '%s/Rifts/Rifts.gpml' % basedir\n",
    "input_rifts_with_failed_rifts = '%s/Rifts/Rifts_with_failed_rifts.gpml' % basedir\n",
    "input_rifts_modelled_additions = '%s/Rifts/Rifts_with_modelled_additions.gpml' % basedir\n",
    "input_rifts_with_modelled_additions_failed_rifts = '%s/Rifts/Rifts_with_modelled_additions_failed_rifts.gpml' % basedir\n",
    "input_rifts_with_modelled_additions_failed_rifts_PZ = '%s/Rifts/Rifts_with_modelled_additions_failed_rifts_PZ.gpml' % basedir\n",
    "\n",
    "topology_features_1000_500 = ['%s/Topos_for_plotting/Convergence_20170716.gpml' % basedir,\n",
    "                              '%s/Topos_for_plotting/Divergence_20170622.gpml' % basedir,\n",
    "                              '%s/Topos_for_plotting/Transforms_20170716.gpml' % basedir,     \n",
    "                              '%s/Topos_for_plotting/Topologies_20170716.gpml' % basedir]\n",
    "\n",
    "topology_features_500_410 = ['/Users/Andrew/Documents/PhD/Models/Domeier_models/Merge/Domeier-EarlyP-merge-Ridges_ASM.gpml',\n",
    "                              '/Users/Andrew/Documents/PhD/Models/Domeier_models/Merge/Domeier-EarlyP-merge-Topologies_ASM.gpml',\n",
    "                              '/Users/Andrew/Documents/PhD/Models/Domeier_models/Merge/Domeier-EarlyP-merge-Trenches_ASM.gpml',\n",
    "                              '/Users/Andrew/Documents/PhD/Models/Domeier_models/Merge/Domeier-EarlyP-merge-Transforms_ASM.gpml',\n",
    "                              '/Users/Andrew/Documents/PhD/Models/Domeier_models/Merge/Domeier-EarlyP-merge-ArbitaryLines_ASM.gpml']\n",
    "\n",
    "topology_features_410_250 = '%s/Global_EarthByte_Paleozoic_plate_boundaries_Matthews_etal.gpml' % basedir2\n",
    "topology_features_250_0 = '%s/Global_EarthByte_Mesozoic-Cenozoic_plate_boundaries_Matthews_etal.gpml' % basedir2\n",
    "\n",
    "rotation_model_1000_500 = pygplates.RotationModel(input_rotation_model_1000_500)\n",
    "rotation_model_500_410 = pygplates.RotationModel(input_rotation_model_500_410)\n",
    "rotation_model_410_0 = pygplates.RotationModel(input_rotation_model_410_0)\n",
    "\n",
    "shapes_1000_500 = pygplates.FeatureCollection(input_shapes_1000_500)\n",
    "shapes_500_410 = pygplates.FeatureCollection(input_shapes_500_410)\n",
    "shapes_410_0 = pygplates.FeatureCollection(input_shapes_410_0)\n",
    "\n",
    "COBs_1000_500 = pygplates.FeatureCollection(input_COBs_1000_500)\n",
    "COBs_500_410 = pygplates.FeatureCollection(input_COBs_500_410)\n",
    "COBs_410_0 = pygplates.FeatureCollection(input_COBs_410_0)\n",
    "\n",
    "rifts = pygplates.FeatureCollection(input_rifts)\n",
    "rifts_with_failed_rifts = pygplates.FeatureCollection(input_rifts_with_failed_rifts)\n",
    "rifts_with_modelled_additions = pygplates.FeatureCollection(input_rifts_modelled_additions)\n",
    "rifts_with_modelled_additions_failed_rifts = pygplates.FeatureCollection(input_rifts_with_modelled_additions_failed_rifts)\n",
    "rifts_with_modelled_additions_failed_rifts_PZ = pygplates.FeatureCollection(input_rifts_with_modelled_additions_failed_rifts_PZ)\n",
    "\n",
    "palaeozoic_rifts = pd.read_csv('%s/Merdith_Rifting_length/450-0_Rifting_length/Sengor_RiftLengthBinned.csv' % basedir3, header=None)\n",
    "#with open ('plen_merge_1250000', 'rb') as fp:\n",
    "#    plen_list = pickle.load(fp)\n",
    "#with open ('plen_merge_10000', 'rb') as fp:\n",
    "#    plen_list2 = pickle.load(fp)\n",
    "\n",
    "multipoints = create_gpml_regular_long_lat_mesh(1)\n",
    "\n",
    "for multipoint in multipoints:\n",
    "    for mp in multipoint.get_all_geometries():\n",
    "        points = mp.to_lat_lon_point_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tidy dataframe, rename columns of palaezoic rift length\n",
    "new_cols = ['time','length']\n",
    "palaeozoic_rifts.columns = new_cols\n",
    "\n",
    "palaeozoic_rifts_list = palaeozoic_rifts['length'].values.tolist() #extract as list\n",
    "palaeozoic_rifts_10myr = palaeozoic_rifts_list[0::10]\n",
    "\n",
    "reversed_palaeozoic_rifts = palaeozoic_rifts_10myr[::-1] #reverse list so that youngest time is at the bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate COB boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "polygons = []\n",
    "for feature in COBs_410_0:\n",
    "    \n",
    "    for geom in feature.get_geometries():\n",
    "        polygon = []\n",
    "        #print feature.get_geometry()\n",
    "    \n",
    "        polygon = feature\n",
    "        polygon.set_geometry(pygplates.PolygonOnSphere(geom))\n",
    "\n",
    "        #print polygon.get_geometry()\n",
    "\n",
    "        polygons.append(polygon)\n",
    "\n",
    "COBs_410_0 = pygplates.FeatureCollection(polygons)\n",
    "#fc.write('pltest.gpmlz')\n",
    "\n",
    "polygons = []\n",
    "for feature in COBs_1000_500:\n",
    "    \n",
    "    for geom in feature.get_geometries():\n",
    "        polygon = []\n",
    "        #print feature.get_geometry()\n",
    "    \n",
    "        polygon = feature\n",
    "        polygon.set_geometry(pygplates.PolygonOnSphere(geom))\n",
    "\n",
    "        #print polygon.get_geometry()\n",
    "\n",
    "        polygons.append(polygon)\n",
    "\n",
    "COBs_1000_500 = pygplates.FeatureCollection(polygons)\n",
    "#fc.write('pltest.gpmlz')\n",
    "\n",
    "polygons = []\n",
    "for feature in COBs_500_410:\n",
    "    \n",
    "    for geom in feature.get_geometries():\n",
    "        polygon = []\n",
    "        #print feature.get_geometry()\n",
    "    \n",
    "        polygon = feature\n",
    "        polygon.set_geometry(pygplates.PolygonOnSphere(geom))\n",
    "\n",
    "        #print polygon.get_geometry()\n",
    "\n",
    "        polygons.append(polygon)\n",
    "\n",
    "COBs_500_410 = pygplates.FeatureCollection(polygons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Continental Arc length over time at distance different increments from nearest COB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_range = [100,\n",
    "                  150,\n",
    "                  200, \n",
    "                  15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_continental_arc_length_1000_500 = dict()\n",
    "\n",
    "for distance in distance_range:\n",
    "    print distance\n",
    "    total_continental_arc_length_1000_500[distance] = []\n",
    "\n",
    "    for time in range(510, 1010, 10):\n",
    "        bi = run_grid_pip(time,points,COBs_1000_500,rotation_model_1000_500)\n",
    "        #print time\n",
    "        \n",
    "        contours = measure.find_contours(bi, 0.5)\n",
    "        #print contours\n",
    "    \n",
    "        pad_hor = np.zeros((1,361))\n",
    "        pad_ver = np.zeros((182,1))\n",
    "        pad1 = np.vstack((bi,pad_hor))\n",
    "        pad2 = np.hstack((pad_ver,pad1))\n",
    "        pad3 = np.hstack((pad2,pad_ver))\n",
    "        contours = measure.find_contours(pad3, 0.5, fully_connected='low')\n",
    "\n",
    "        contour_polygons = []\n",
    "        cobter_feature_collection = []\n",
    "        for n,cp in enumerate(contours):\n",
    "\n",
    "            cp[:,1] = cp[:,1]-1\n",
    "            cp[:,0] = cp[:,0]-1\n",
    "\n",
    "\n",
    "            cp[np.where(cp[:,0]<0.),0] = 0\n",
    "            cp[np.where(cp[:,0]>180.),0] = 180\n",
    "            cp[np.where(cp[:,1]<0.),1] = 0\n",
    "            cp[np.where(cp[:,1]>360.),1] = 360\n",
    "            cpf = pygplates.PolygonOnSphere(zip(cp[:,0]-90,cp[:,1]-180))\n",
    "            contour_polygons.append(cpf)\n",
    "            cobter_feature_collection.append(cpf)\n",
    "        \n",
    "        resolved_topologies = []\n",
    "        shared_boundary_sections = []\n",
    "        all_tesselated_shared_sub_segment = []\n",
    "        continental_arcs = []\n",
    "\n",
    "        pygplates.resolve_topologies(topology_features_1000_500, rotation_model_1000_500, resolved_topologies, time, shared_boundary_sections)\n",
    "\n",
    "        total_length = 0.\n",
    "\n",
    "        for shared_boundary_section in shared_boundary_sections:\n",
    "\n",
    "            if shared_boundary_section.get_feature().get_feature_type() == pygplates.FeatureType.gpml_subduction_zone:\n",
    "\n",
    "                for shared_sub_segment in shared_boundary_section.get_shared_sub_segments():\n",
    "                    tmp = shared_sub_segment.get_resolved_geometry()\n",
    "                    tesselated_shared_sub_segment = tmp.to_tessellated(np.radians(0.1))      \n",
    "\n",
    "                    all_tesselated_shared_sub_segment.append(tesselated_shared_sub_segment)\n",
    "\n",
    "                    for segment in tesselated_shared_sub_segment.get_segments():\n",
    "                        count = 0.\n",
    "                        for COB in contour_polygons:\n",
    "                            if COB.get_area()*pygplates.Earth.mean_radius_in_kms**2 > 500000:\n",
    "                                distance_radians = pygplates.GeometryOnSphere.distance(segment.get_arc_point(0.5), \n",
    "                                                                                       COB)\n",
    "                                distance_kms = distance_radians * pygplates.Earth.mean_radius_in_kms\n",
    "                                if distance_kms < distance:\n",
    "                                    total_length += segment.get_arc_length() * pygplates.Earth.mean_radius_in_kms\n",
    "                                    count+=1.\n",
    "                                    if count > 1:\n",
    "                                        print 'Double-Dipping!!'\n",
    "\n",
    "                                    break\n",
    "        total_continental_arc_length_1000_500[distance].append(total_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_continental_arc_length_500_410 = dict()\n",
    "\n",
    "for distance in distance_range:\n",
    "    print distance\n",
    "    total_continental_arc_length_500_410[distance] = []\n",
    "\n",
    "    for time in range(420, 510, 10):\n",
    "        \n",
    "        bi = run_grid_pip(time,points,COBs_500_410,rotation_model_500_410)\n",
    "        \n",
    "        contours = measure.find_contours(bi, 0.5)\n",
    "    \n",
    "        pad_hor = np.zeros((1,361))\n",
    "        pad_ver = np.zeros((182,1))\n",
    "        pad1 = np.vstack((bi,pad_hor))\n",
    "        pad2 = np.hstack((pad_ver,pad1))\n",
    "        pad3 = np.hstack((pad2,pad_ver))\n",
    "        contours = measure.find_contours(pad3, 0.5, fully_connected='low')\n",
    "\n",
    "        contour_polygons = []\n",
    "        cobter_feature_collection = []\n",
    "        for n,cp in enumerate(contours):\n",
    "\n",
    "            cp[:,1] = cp[:,1]-1\n",
    "            cp[:,0] = cp[:,0]-1\n",
    "\n",
    "            cp[np.where(cp[:,0]<0.),0] = 0\n",
    "            cp[np.where(cp[:,0]>180.),0] = 180\n",
    "            cp[np.where(cp[:,1]<0.),1] = 0\n",
    "            cp[np.where(cp[:,1]>360.),1] = 360\n",
    "            cpf = pygplates.PolygonOnSphere(zip(cp[:,0]-90,cp[:,1]-180))\n",
    "            contour_polygons.append(cpf)\n",
    "            cobter_feature_collection.append(cpf)\n",
    "\n",
    "        resolved_topologies = []\n",
    "        shared_boundary_sections = []\n",
    "        all_tesselated_shared_sub_segment = []\n",
    "        continental_arcs = []\n",
    "\n",
    "        pygplates.resolve_topologies(topology_features_500_410, rotation_model_500_410, resolved_topologies, time, shared_boundary_sections)\n",
    "\n",
    "        total_length = 0.\n",
    "\n",
    "        for shared_boundary_section in shared_boundary_sections:\n",
    "\n",
    "            if shared_boundary_section.get_feature().get_feature_type() == pygplates.FeatureType.gpml_subduction_zone:\n",
    "\n",
    "                for shared_sub_segment in shared_boundary_section.get_shared_sub_segments():\n",
    "                    tmp = shared_sub_segment.get_resolved_geometry()\n",
    "                    tesselated_shared_sub_segment = tmp.to_tessellated(np.radians(0.1))      \n",
    "\n",
    "                    all_tesselated_shared_sub_segment.append(tesselated_shared_sub_segment)\n",
    "\n",
    "                    for segment in tesselated_shared_sub_segment.get_segments():\n",
    "                        count = 0.\n",
    "                        for COB in contour_polygons:\n",
    "                            if COB.get_area()*pygplates.Earth.mean_radius_in_kms**2 > 500000:\n",
    "                                distance_radians = pygplates.GeometryOnSphere.distance(segment.get_arc_point(0.5), \n",
    "                                                                                       COB)\n",
    "                                distance_kms = distance_radians * pygplates.Earth.mean_radius_in_kms\n",
    "                                if distance_kms < distance:\n",
    "                                    total_length += segment.get_arc_length() * pygplates.Earth.mean_radius_in_kms\n",
    "                                    count+=1.\n",
    "                                    if count > 1:\n",
    "                                        print 'Double-Dipping!!'\n",
    "\n",
    "                                    break\n",
    "        total_continental_arc_length_500_410[distance].append(total_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "total_continental_arc_length_410_250 = dict()\n",
    "\n",
    "for distance in distance_range:\n",
    "    print distance\n",
    "    total_continental_arc_length_410_250[distance] = []\n",
    "\n",
    "    for time in range(260, 420, 10):\n",
    "        \n",
    "        bi = run_grid_pip(time,points,COBs_410_0,rotation_model_410_0)\n",
    "        \n",
    "        contours = measure.find_contours(bi, 0.5)\n",
    "    \n",
    "        pad_hor = np.zeros((1,361))\n",
    "        pad_ver = np.zeros((182,1))\n",
    "        pad1 = np.vstack((bi,pad_hor))\n",
    "        pad2 = np.hstack((pad_ver,pad1))\n",
    "        pad3 = np.hstack((pad2,pad_ver))\n",
    "        contours = measure.find_contours(pad3, 0.5, fully_connected='low')\n",
    "\n",
    "        contour_polygons = []\n",
    "        cobter_feature_collection = []\n",
    "        for n,cp in enumerate(contours):\n",
    "\n",
    "            cp[:,1] = cp[:,1]-1\n",
    "            cp[:,0] = cp[:,0]-1\n",
    "\n",
    "            cp[np.where(cp[:,0]<0.),0] = 0\n",
    "            cp[np.where(cp[:,0]>180.),0] = 180\n",
    "            cp[np.where(cp[:,1]<0.),1] = 0\n",
    "            cp[np.where(cp[:,1]>360.),1] = 360\n",
    "            cpf = pygplates.PolygonOnSphere(zip(cp[:,0]-90,cp[:,1]-180))\n",
    "            contour_polygons.append(cpf)\n",
    "            cobter_feature_collection.append(cpf)\n",
    "\n",
    "        resolved_topologies = []\n",
    "        shared_boundary_sections = []\n",
    "        all_tesselated_shared_sub_segment = []\n",
    "        continental_arcs = []\n",
    "\n",
    "        pygplates.resolve_topologies(topology_features_410_250, rotation_model_410_0, resolved_topologies, time, shared_boundary_sections)\n",
    " \n",
    "        total_length = 0.\n",
    "\n",
    "        for shared_boundary_section in shared_boundary_sections:\n",
    "\n",
    "            if shared_boundary_section.get_feature().get_feature_type() == pygplates.FeatureType.gpml_subduction_zone:\n",
    "\n",
    "                for shared_sub_segment in shared_boundary_section.get_shared_sub_segments():\n",
    "                    tmp = shared_sub_segment.get_resolved_geometry()\n",
    "                    tesselated_shared_sub_segment = tmp.to_tessellated(np.radians(0.1))      \n",
    "\n",
    "                    all_tesselated_shared_sub_segment.append(tesselated_shared_sub_segment)\n",
    "\n",
    "                    for segment in tesselated_shared_sub_segment.get_segments():\n",
    "                        count = 0.\n",
    "                        for COB in contour_polygons:\n",
    "                            if COB.get_area()*pygplates.Earth.mean_radius_in_kms**2 > 500000:\n",
    "                                distance_radians = pygplates.GeometryOnSphere.distance(segment.get_arc_point(0.5), \n",
    "                                                                                       COB)\n",
    "                                distance_kms = distance_radians * pygplates.Earth.mean_radius_in_kms\n",
    "                                if distance_kms < distance:\n",
    "                                    total_length += segment.get_arc_length() * pygplates.Earth.mean_radius_in_kms\n",
    "                                    count+=1.\n",
    "                                    if count > 1:\n",
    "                                        print 'Double-Dipping!!'\n",
    "\n",
    "                                    break\n",
    "        total_continental_arc_length_410_250[distance].append(total_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_continental_arc_length_250_0 = dict()\n",
    "\n",
    "for distance in distance_range:\n",
    "    print distance\n",
    "    total_continental_arc_length_250_0[distance] = []\n",
    "\n",
    "    for time in range(0, 260, 10):\n",
    "\n",
    "        bi = run_grid_pip(time,points,COBs_410_0,rotation_model_410_0)\n",
    "        #print time\n",
    "        \n",
    "        contours = measure.find_contours(bi, 0.5)\n",
    "        #print contours\n",
    "    \n",
    "        pad_hor = np.zeros((1,361))\n",
    "        pad_ver = np.zeros((182,1))\n",
    "        pad1 = np.vstack((bi,pad_hor))\n",
    "        pad2 = np.hstack((pad_ver,pad1))\n",
    "        pad3 = np.hstack((pad2,pad_ver))\n",
    "        contours = measure.find_contours(pad3, 0.5, fully_connected='low')\n",
    "\n",
    "        contour_polygons = []\n",
    "        cobter_feature_collection = []\n",
    "        for n,cp in enumerate(contours):\n",
    "            #print cp[:,1]\n",
    "            #print cp[:,1]+1\n",
    "            cp[:,1] = cp[:,1]-1\n",
    "            cp[:,0] = cp[:,0]-1\n",
    "            #print cp[:,0][::10]\n",
    "            #print cp\n",
    "\n",
    "            cp[np.where(cp[:,0]<0.),0] = 0\n",
    "            cp[np.where(cp[:,0]>180.),0] = 180\n",
    "            cp[np.where(cp[:,1]<0.),1] = 0\n",
    "            cp[np.where(cp[:,1]>360.),1] = 360\n",
    "            cpf = pygplates.PolygonOnSphere(zip(cp[:,0]-90,cp[:,1]-180))\n",
    "            contour_polygons.append(cpf)\n",
    "            cobter_feature_collection.append(cpf)\n",
    "\n",
    "        #print time\n",
    "        resolved_topologies = []\n",
    "        shared_boundary_sections = []\n",
    "        all_tesselated_shared_sub_segment = []\n",
    "        continental_arcs = []\n",
    "        #reconstructed_COBs = []\n",
    "\n",
    "\n",
    "        pygplates.resolve_topologies(topology_features_250_0, rotation_model_410_0, resolved_topologies, time, shared_boundary_sections)\n",
    "\n",
    "        total_length = 0.\n",
    "\n",
    "        for shared_boundary_section in shared_boundary_sections:\n",
    "\n",
    "            if shared_boundary_section.get_feature().get_feature_type() == pygplates.FeatureType.gpml_subduction_zone:\n",
    "\n",
    "                for shared_sub_segment in shared_boundary_section.get_shared_sub_segments():\n",
    "                    tmp = shared_sub_segment.get_resolved_geometry()\n",
    "                    tesselated_shared_sub_segment = tmp.to_tessellated(np.radians(0.1))      \n",
    "\n",
    "                    all_tesselated_shared_sub_segment.append(tesselated_shared_sub_segment)\n",
    "\n",
    "                    for segment in tesselated_shared_sub_segment.get_segments():\n",
    "                        count = 0.\n",
    "                        for COB in contour_polygons:\n",
    "                            if COB.get_area()*pygplates.Earth.mean_radius_in_kms**2 > 500000:\n",
    "                                distance_radians = pygplates.GeometryOnSphere.distance(segment.get_arc_point(0.5), \n",
    "                                                                                       COB)\n",
    "                                distance_kms = distance_radians * pygplates.Earth.mean_radius_in_kms\n",
    "                                if distance_kms < distance:\n",
    "                                    total_length += segment.get_arc_length() * pygplates.Earth.mean_radius_in_kms\n",
    "                                    count+=1.\n",
    "                                    if count > 1:\n",
    "                                        print 'Double-Dipping!!'\n",
    "\n",
    "                                    break\n",
    "        total_continental_arc_length_250_0[distance].append(total_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new dictionary of continental arc length\n",
    "total_continental_arc_length = defaultdict(list)\n",
    "dicts = [total_continental_arc_length_250_0, total_continental_arc_length_410_250, total_continental_arc_length_500_410,\n",
    "         total_continental_arc_length_1000_500]\n",
    "\n",
    "for d in dicts:\n",
    "    for k,v in d.items():\n",
    "        total_continental_arc_length[k] = total_continental_arc_length[k] + v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine oceanic arc length by subtracting our threshold from total\n",
    "c = total_continental_arc_length[15000]\n",
    "d = total_continental_arc_length[150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this calculates oceanic arcs based on subtracting continental arcs from total arc length\n",
    "e= []\n",
    "for i,j in zip(c,d):\n",
    "    e.append(i-j)\n",
    "    \n",
    "f = {'ocean':e[:]}\n",
    "total_continental_arc_length.update(f)\n",
    "total_continental_arc_length.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_times_1 = np.arange(0,1010,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot arc length\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(30,12),facecolor='w', edgecolor='k')\n",
    "ax.plot(plotting_times_1, total_continental_arc_length[100], linewidth=3, alpha=0.4, label='100 km threshold')\n",
    "ax.plot(plotting_times_1, total_continental_arc_length[150], linewidth=3, label='150 km threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "a = total_continental_arc_length\n",
    "\n",
    "with open('cont_arc_length.pickle', 'wb') as handle:\n",
    "    pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('cont_arc_length.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "my_dict = total_continental_arc_length\n",
    "\n",
    "with open('mycsvfile.csv', 'wb') as f:  # Just use 'w' mode in 3.x\n",
    "    w = csv.DictWriter(f, my_dict.keys())\n",
    "    w.writeheader()\n",
    "    w.writerow(my_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Rift Length from Neoproterozoic model, link to Phanerozoic Rift Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rift_dict = {'rifts_modelled_additions_failed_rifts': rifts_with_modelled_additions_failed_rifts,\n",
    "             'rifts_modelled_additions': rifts_with_modelled_additions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract total rift length through time for various files\n",
    "#default rifts as best constrained by geology\n",
    "\n",
    "total_rift_length = dict()\n",
    "\n",
    "for rift_type, rift_lengths in rift_dict.items():\n",
    "    print rift_type\n",
    "    total_rift_length[rift_type] = []\n",
    "    for time in range(460,1010,10):\n",
    "        rift_length_total = 0.\n",
    "        for rift in rift_lengths:\n",
    "            rift_length = rift.get_geometry().get_arc_length()\n",
    "            individual_rift_length_kms = rift_length * pygplates.Earth.mean_radius_in_kms\n",
    "            tmp_valid_time = np.arange(int(rift.get_valid_time()[1]), int(rift.get_description())+1, 1)\n",
    "            if (rift.get_valid_time()[0] >= time) and (int(rift.get_description()) <= time):\n",
    "                rift_length_total+=individual_rift_length_kms\n",
    "\n",
    "        total_rift_length[rift_type].append(rift_length_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#organise rifts from 0-1000\n",
    "for key in total_rift_length:\n",
    "    temp_list = []\n",
    "    temp_list.extend(palaeozoic_rifts_10myr)\n",
    "    temp_list.extend(total_rift_length[key])\n",
    "    total_rift_length[key] = temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = total_rift_length['rifts_modelled_additions_failed_rifts']\n",
    "\n",
    "with open('my_rift_csvfile.csv', 'wb') as f:  # Just use 'w' mode in 3.x\n",
    "    w = csv.writer(f, my_dict)\n",
    "    w.writerow(my_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to create a stack plot of just neoproterozoic rifts\n",
    "l_list = []\n",
    "rift_names = []\n",
    "times = []\n",
    "for rift in rift_dict['rifts_modelled_additions_failed_rifts']:\n",
    "    rift_names.append(rift.get_name())\n",
    "    times.append(rift.get_valid_time())\n",
    "    l = GetRiftLength(rift)\n",
    "    l_list.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#stack plot of rift length from the Neoproterozoic\n",
    "num_colours = len(rift_names)\n",
    "cm = plt.get_cmap('viridis')\n",
    "cNorm = colors.Normalize(vmin=0, vmax=num_colours)\n",
    "scalarMap = mplcm.ScalarMappable(norm=cNorm, cmap=cm)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(30,10), facecolor='w', edgecolor='k')\n",
    "ax.set_color_cycle([scalarMap.to_rgba(i) for i in range(num_colours)])\n",
    "ax.stackplot(plotting_times_Mer17Dom16,l_list)\n",
    "ax.tick_params(axis='x', labelsize=tick_fontsize)\n",
    "ax.tick_params(axis='y', labelsize=tick_fontsize)\n",
    "ax.set_xlim(1000,450)\n",
    "ax.set_xticks(np.arange(450,1050,50))\n",
    "ax.xaxis.grid(True, alpha=.5)\n",
    "ax.yaxis.grid(True, alpha=.5)\n",
    "ax.set_xlabel('Time (Ma)', fontsize=axes_title_fontsize)\n",
    "ax.set_ylabel('Length (km)', fontsize=axes_title_fontsize)\n",
    "ax.legend(rift_names, loc='lower center', ncol=12,bbox_to_anchor=(0.5,-0.4),fontsize=leg_font)\n",
    "#plt.savefig(\"Rift-length-1000-450-stacked.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set colour scale\n",
    "num_colours = 9\n",
    "cm = plt.get_cmap('viridis')\n",
    "cNorm = colors.Normalize(vmin=0, vmax=num_colours)\n",
    "scalarMap = mplcm.ScalarMappable(norm=cNorm, cmap=cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_times_Mer17EPSL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just arc length\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(30,12),facecolor='w', edgecolor='k')\n",
    "ax.plot(plotting_times_Mer17EPSL, total_continental_arc_length[100], linewidth=3, color='k', label='100 km')\n",
    "ax.plot(plotting_times_Mer17EPSL, total_continental_arc_length[200], linewidth=3, color='k', label='200 km')\n",
    "ax.plot(plotting_times_Mer17EPSL, total_continental_arc_length[15000], linewidth=3, label='15000 km')\n",
    "ax.fill_between(plotting_times_Mer17EPSL, total_continental_arc_length[100], total_continental_arc_length[200], color='gray', alpha=0.3)\n",
    "ax.tick_params(axis='x', labelsize=tick_fontsize)\n",
    "ax.tick_params(axis='y', labelsize=tick_fontsize)\n",
    "ax.set_xlim(1000,0)\n",
    "ax.set_xlabel('Time (Ma)', fontsize=axes_title_fontsize)\n",
    "ax.set_ylabel('Length (km)', fontsize=axes_title_fontsize)\n",
    "ax.set_xticks(np.arange(0,1100,100))\n",
    "ax.xaxis.grid(True, alpha=.5)\n",
    "ax.yaxis.grid(True, alpha=.5)\n",
    "labelLines(plt.axes(ax).get_lines(),align=False,fontsize=18)\n",
    "\n",
    "#plt.savefig(\"Arc-length-1000-0-thresholds.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot just rift length\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(30,12),facecolor='w', edgecolor='k')\n",
    "for data_labels, data_dict in total_rift_length.items():\n",
    "    ax.plot(plotting_times_Mer17EPSL,data_dict, label=data_labels, linewidth=3)\n",
    "ax.tick_params(axis='x', labelsize=tick_fontsize)\n",
    "ax.tick_params(axis='y', labelsize=tick_fontsize)\n",
    "ax.set_xlim(1000,0)\n",
    "ax.set_xlabel('Time (Ma)', fontsize=axes_title_fontsize)\n",
    "ax.set_ylabel('Length (km)', fontsize=axes_title_fontsize)\n",
    "ax.set_xticks(np.arange(0,1050,50))\n",
    "ax.xaxis.grid(True, alpha=.5)\n",
    "ax.yaxis.grid(True, alpha=.5)\n",
    "ax.legend(ncol=2,loc='lower center',bbox_to_anchor=(0.5,-0.4),fontsize=32)\n",
    "#plt.savefig(\"Rift_length_1000-0.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(30,12),facecolor='w', edgecolor='k')\n",
    "ax.plot(plotting_times_Mer17EPSL, plen_list, linewidth=linewidth, label='Continental Perimeter Length (5,000 km2 threshold)', color='k')\n",
    "ax.plot(plotting_times_Mer17EPSL, plen_list2, linewidth=linewidth, label='Continental Perimeter Length (5,000,000 km2 threshold)', color='k', ls='--')\n",
    "ax.tick_params(axis='y', labelsize=tick_fontsize)\n",
    "ax.tick_params(axis='x', labelsize=tick_fontsize)\n",
    "ax.set_xlim(1000,0)\n",
    "ax.set_ylabel('Continental Perimeter Length (km)', fontsize=axes_title_fontsize)\n",
    "ax.set_xlabel('Time (Ma)', fontsize=axes_title_fontsize)\n",
    "ax.set_xticks(np.arange(0,1050,50))\n",
    "ax.xaxis.grid(True, alpha=.5)\n",
    "ax.yaxis.grid(True, alpha=.5)\n",
    "ax.legend(ncol=1,loc='lower center',bbox_to_anchor=(0.5,-0.3),fontsize=32)\n",
    "#plt.savefig(\"Continental-perimeter_length_1000-0.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot everything (master version)\n",
    "fig, ax1 = plt.subplots(nrows=1, ncols=1, figsize=(30,12),facecolor='w', edgecolor='k')\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(plotting_times_Mer17EPSL,total_continental_arc_length[100], linewidth=linewidth, alpha=0.2, label='Continental Arc Length (100 km threshold)')\n",
    "ax1.plot(plotting_times_Mer17EPSL,total_continental_arc_length[200], linewidth=linewidth, alpha=0.2, label='Continental Arc Length (200 km threshold)')\n",
    "ax1.plot(plotting_times_Mer17EPSL,total_continental_arc_length[300], linewidth=linewidth, label='Continental Arc Length (300 km threshold)')\n",
    "for data_labels, data_dict in total_rift_length.items():\n",
    "    ax1.plot(plotting_times_Mer17EPSL, data_dict, label=data_labels)\n",
    "ax2.plot(plotting_times_Mer17EPSL, plen_list, linewidth=linewidth, label='COB', color='k', alpha=0.7)\n",
    "ax2.plot(plotting_times_Mer17EPSL, plen_list2, linewidth=linewidth, label='COB2', color='k', ls='--', alpha=0.7)\n",
    "ax1.fill_between(plotting_times_Mer17EPSL, total_continental_arc_length[200], total_continental_arc_length[300], alpha=0.1)\n",
    "ax1.tick_params(axis='x', labelsize=tick_fontsize)\n",
    "ax1.tick_params(axis='y', labelsize=tick_fontsize)\n",
    "ax2.tick_params(axis='y', labelsize=tick_fontsize)\n",
    "ax1.set_xlim(1000,0)\n",
    "ax1.set_xticks(np.arange(0,1050,50))\n",
    "ax1.set_xlabel('Time (Ma)', fontsize=axes_title_fontsize)\n",
    "ax1.set_ylabel('Arc/Rift Length (km)', fontsize=axes_title_fontsize)\n",
    "ax2.set_ylabel('COB Length (km)', fontsize=axes_title_fontsize)\n",
    "ax1.xaxis.grid(True, alpha=.5)\n",
    "ax1.yaxis.grid(True, alpha=.5)\n",
    "ax2.yaxis.grid(True, alpha=.7, ls='-.')\n",
    "ax1.legend(ncol=2,loc='lower center',bbox_to_anchor=(0.5,-0.5),fontsize=32)\n",
    "ax2.legend(fontsize=32)\n",
    "#plt.savefig(\"Arc_Rift_length-1000-0.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
