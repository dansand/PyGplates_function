{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pygplates as pgp\n",
    "import os\n",
    "import pandas as pd\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Torsvik_2012 poles\n",
    "pmag_file_Rodinia_A_0age = '/Users/Andrew/Documents/PhD/Models/Nordic_Convention_files/Rodinia_Poles/Rodinia_global_keypoles_Haraldvangen_FINAL_A_POLES_0age.csv'\n",
    "pmag_file_Rodinia_A = '/Users/Andrew/Documents/PhD/Models/Nordic_Convention_files/Rodinia_Poles/Rodinia_global_keypoles_Haraldvangen_FINAL_A_POLES.csv'\n",
    "pmag_file_Rodinia_B_0age = '/Users/Andrew/Documents/PhD/Models/Nordic_Convention_files/Rodinia_Poles/Rodinia_global_keypoles_Haraldvangen_FINAL_B_POLES_0age.csv'\n",
    "pmag_file_Rodinia_B = '/Users/Andrew/Documents/PhD/Models/Nordic_Convention_files/Rodinia_Poles/Rodinia_global_keypoles_Haraldvangen_FINAL_B_POLES.csv'\n",
    "\n",
    "pmag_Rod_A_0 = pd.read_csv(pmag_file_Rodinia_A_0age)\n",
    "pmag_Rod_A = pd.read_csv(pmag_file_Rodinia_A)\n",
    "pmag_Rod_B_0 = pd.read_csv(pmag_file_Rodinia_B_0age)\n",
    "pmag_Rod_B = pd.read_csv(pmag_file_Rodinia_B)\n",
    "\n",
    "# test coastline sets\n",
    "#polyFile = '/Users/Andrew/Documents/PhD/Models/Golonka_Wright_Model/Phanerozoic_EarthByte_Coastlines.gpml'\n",
    "polyFile = '/Users/Andrew/Documents/PhD/Models/Rodinia_Models/Lis_model_amends/Rodinia_shapes.gpml'\n",
    "\n",
    "#match *_0 with EarthByte Coastlines\n",
    "#match the otherws with Rodinia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers = pmag_Rod_A.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BLOCK', 'TERRANE', 'RESULT#', 'COMPONENT', 'TESTS', 'TILT', 'SLAT',\n",
       "       'SLONG', 'B', 'N', 'DEC', 'INC', 'abs(I)', 'KD', 'ED95', 'PLAT',\n",
       "       'PLONG', 'DP', 'DM', 'A95', '%REV', 'DEMAGCODE', '40', '24', '10',\n",
       "       '16', '2', '3', '4', '5', '6', 'Q', 'BD_grade', 'nominal_age',\n",
       "       'lomagage', 'himagage', 'REF/method', 'ROCKNAME', 'POLE AUTHORS',\n",
       "       'YEAR', 'JOURNAL', 'VOLUME', 'VPAGES', 'TITLE'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Iterate through palaeomagnetic pole dataset (pmag_data) and build lists of unique terranes and continental blocks\n",
    "terrane_list = []\n",
    "block_list = []\n",
    "\n",
    "#pmag_data = pmag_Rod_A_0 \n",
    "#pmag_data = pmag_Rod_A \n",
    "pmag_data = pmag_Rod_B_0 \n",
    "#pmag_data = pmag_Rod_B \n",
    "\n",
    "for i, terrane in enumerate(pmag_data.TERRANE .values):\n",
    "    \n",
    "    if terrane not in terrane_list:\n",
    "        \n",
    "        terrane_list.append(pmag_data.TERRANE [i])\n",
    "        \n",
    "        \n",
    "for j, block in enumerate(pmag_data.BLOCK .values):\n",
    "    \n",
    "    if block not in block_list:\n",
    "        \n",
    "        block_list.append(pmag_data.BLOCK [j])\n",
    "        \n",
    "#######\n",
    "\n",
    "# Iterate through palaeomagnetic pole data set and build Pandas DataFrame of required data\n",
    "pole_list = []\n",
    "\n",
    "for terrane in terrane_list:\n",
    "    \n",
    "    for k, item in enumerate(pmag_data.TERRANE .values):\n",
    "        \n",
    "        if item == terrane:\n",
    "            \n",
    "            # Create dictionary for DataFrame\n",
    "            pole_list.append({'Terrane': pmag_data.TERRANE  [k], 'Block': pmag_data.BLOCK [k],'Formation': pmag_data.ROCKNAME [k], \n",
    "                              'PLat': pmag_data.PLAT [k], 'PLon': pmag_data.PLONG [k], 'SLat': pmag_data.SLAT [k],'SLon': pmag_data.SLONG[k], \n",
    "                              'AgeNominal': pmag_data.nominal_age [k], 'AgeLower': pmag_data.lomagage[k], \n",
    "                              'AgeUpper': pmag_data.himagage[k], 'a95': pmag_data.A95[k], 'N': pmag_data.N[k],\n",
    "                              'k': pmag_data.KD[k], 'Dec': pmag_data.DEC[k], 'Inc': pmag_data.INC [k], 'Q': pmag_data.Q[k]})\n",
    "            \n",
    "# Create and display Pandas DataFrame   \n",
    "raw_polesDF = pd.DataFrame(pole_list)\n",
    "#raw_polesDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform 'point in polygon' test to assign plate ID to pole based on sampling location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polygon test complete. Located and assigned plate ID's to 23 poles.\n"
     ]
    }
   ],
   "source": [
    "featureCollection = pgp.FeatureCollectionFileFormatRegistry()\n",
    "featureSet = featureCollection.read(polyFile)\n",
    " \n",
    "try:\n",
    "    featureSet = featureCollection.read(polyFile)\n",
    "\n",
    "except pgp.OpenFileForReadingError:\n",
    "    print \"Doesn't work like that silly.\"\n",
    "\n",
    "\n",
    "plateIDs = []\n",
    "plates = []\n",
    "\n",
    "\n",
    "# Array to contain correct line numbers from full dataset to make sure the correct values are assiciated the correct poles.\n",
    "line = []\n",
    "count = 0\n",
    "polyCount = 0\n",
    "\n",
    "for i in xrange(0, len(raw_polesDF)):\n",
    "    \n",
    "    count = count + 1\n",
    "    \n",
    "    if pd.isnull(raw_polesDF.SLat[i]) == False:\n",
    "        inputlatLon = pgp.LatLonPoint(raw_polesDF.SLat[i], raw_polesDF.SLon[i])\n",
    "        latLonPoint = pgp.convert_lat_lon_point_to_point_on_sphere(inputlatLon)\n",
    "        \n",
    "    for feature in featureSet:\n",
    "        for property in feature:\n",
    "            propertyName = property.get_name()\n",
    "            \n",
    "        \n",
    "            if propertyName.get_name() == \"unclassifiedGeometry\":\n",
    "            #if propertyName.get_name() == \"outlineOf\":\n",
    "        \n",
    "                polygons = property.get_value().get_polygon()\n",
    "                #print polygons\n",
    "\n",
    "                isPoly = polygons.is_point_in_polygon(latLonPoint)\n",
    "                #print isPoly\n",
    "\n",
    "                if isPoly == True:\n",
    "                    \n",
    "                    if feature.get_reconstruction_plate_id() != 346:\n",
    "                        \n",
    "                        plateIDs.append(feature.get_reconstruction_plate_id())\n",
    "                        plates.append(feature.get_name())\n",
    "                        line.append(i)\n",
    "                    \n",
    "                    # Uncomment this line for verbose output\n",
    "                    # print \"Count: \" + str(count) + \", Line: \" + str(line[polyCount]) + \", Value: \" + str(raw_polesDF.a95[i]) + \\\n",
    "                    # \", PlateID: \" + str(plateIDs[polyCount]) + \", Plate: \" + str(plates[polyCount])\n",
    "\n",
    "                    polyCount = polyCount + 1\n",
    "\n",
    "print \"Polygon test complete. Located and assigned plate ID's to\", len(plateIDs), \"poles.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and populate FeatureCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Amazonia', 'Australia-N', 'Australia-S', 'Australia-W', 'Baltica',\n",
       "       'Congo', 'Congo-Sao Francisco', 'India', 'Kalahari', 'Laurentia',\n",
       "       'Laurentia-Scotland', 'Laurentia-Svalbard', 'Rio Plata',\n",
       "       'Siberia-Aldan', 'Siberia-west', 'South China', 'Tarim',\n",
       "       'West Africa'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueBlocks = np.unique(raw_polesDF[[\"Block\"]])\n",
    "uniqueBlocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Amazonia'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueBlocks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "VGP Features created\n"
     ]
    }
   ],
   "source": [
    "# Loop through list of poles and produce GPML file of multiple VGPs.\n",
    "poleLat = []\n",
    "poleLon = []\n",
    "poleName = []\n",
    "poleInc = []\n",
    "poleDec = []\n",
    "poleSiteLat = []\n",
    "poleSiteLon = []\n",
    "poleNominalAge = []\n",
    "\n",
    "poleA95 = []\n",
    "plateID = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in xrange(0, len(plateIDs)):\n",
    "    \n",
    "    if raw_polesDF.Block[line[i]] in uniqueBlocks:#\"Amazonia-Guyana\":# or raw_polesDF.Block[line[i]] == \"Australia-N\":\n",
    "        \n",
    "        poleLat.append(raw_polesDF.PLat[line[i]])\n",
    "        poleLon.append(raw_polesDF.PLon[line[i]])\n",
    "        poleName.append(raw_polesDF.Formation[line[i]])\n",
    "        poleInc.append(raw_polesDF.Inc[line[i]])\n",
    "        poleDec.append(raw_polesDF.Dec[line[i]])\n",
    "        poleSiteLat.append(raw_polesDF.SLat[line[i]])\n",
    "        poleSiteLon.append(raw_polesDF.SLon[line[i]])\n",
    "        poleNominalAge.append(raw_polesDF.AgeNominal[line[i]])\n",
    "        poleA95.append(raw_polesDF.a95[line[i]])\n",
    "        plateID.append(plateIDs[i])\n",
    "\n",
    "        count = count + 1\n",
    "        print count\n",
    "    \n",
    " \n",
    "# Create new GPlates Feature Collection\n",
    "vpgFeatureCollection = pgp.FeatureCollection()\n",
    "    \n",
    "# Create new GPlates feature 'VirtualGeomagneticPole'.\n",
    "# Pole lat, pole lon, pole name, and reconstruction plate ID added within PointOnSphere method.\n",
    "# Inc, Dec, A95, Age and Sample site lat/lon values to added within 'other_properties' method.\n",
    "\n",
    "for j in xrange(0, count):\n",
    "\n",
    "    vgpFeature = pgp.Feature.create_reconstructable_feature(\n",
    "                 pgp.FeatureType.create_gpml('VirtualGeomagneticPole'),\n",
    "                 pgp.PointOnSphere([np.float(poleLat[j]), np.float(poleLon[j])]),\n",
    "                 name = poleName[j],\n",
    "                 reconstruction_plate_id = plateID[j],\n",
    "                 #valid_time=(np.float(poleAgeUpperLimit), np.float(poleAgeLowerLimit)),\n",
    "                 other_properties = [(pgp.PropertyName.create_gpml('averageInclination'), pgp.XsDouble(poleInc[j])),\n",
    "                                     (pgp.PropertyName.create_gpml('averageDeclination'), pgp.XsDouble(poleDec[j])),\n",
    "                                     (pgp.PropertyName.create_gpml('poleA95'), pgp.XsDouble(poleA95[j])),\n",
    "                                     (pgp.PropertyName.create_gpml('averageAge'), pgp.XsDouble(poleNominalAge[j])),\n",
    "                                     (pgp.PropertyName.create_gpml('averageSampleSitePosition'),\n",
    "                                      pgp.GmlPoint(pgp.PointOnSphere([np.float(poleSiteLat[j]), \n",
    "                                                                      np.float(poleSiteLon[j])])))])\n",
    "\n",
    "    # Add newly created feature to existing Feature Collection\n",
    "    vpgFeatureCollection.add(vgpFeature)\n",
    "    \n",
    "print \"VGP Features created\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate GPML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palaeomagnetic pole data successfully exported in GPML format\n"
     ]
    }
   ],
   "source": [
    "# Generate GPML output file\n",
    "#gpmlOutputFile= 'pmag_Rod_A_0.gpml' \n",
    "#gpmlOutputFile = 'pmag_Rod_A.gpml'\n",
    "#gpmlOutputFile = 'pmag_Rod_B_0.gpml' \n",
    "#gpmlOutputFile = 'pmag_Rod_B.gpml'\n",
    "\n",
    "gpmlOutputFile = 'pmag_Rod_B_0_Rodcoasts.gpml'\n",
    "\n",
    "\n",
    "\n",
    "# Check for existing output directory and create it if not found\n",
    "if not os.path.exists(\"output\"):\n",
    "    os.makedirs(\"output\")\n",
    "\n",
    "# Check for existing output file with same name and remove if found\n",
    "if os.path.isfile(\"output/\" + str(gpmlOutputFile)):\n",
    "    os.remove(\"output/\" + str(gpmlOutputFile))\n",
    "\n",
    "# Check to make sure vgpFeatureCollection (feature collection) is not empty before writing to file\n",
    "if len(vpgFeatureCollection) != 0:\n",
    "    outputFeatureCollection = pgp.FeatureCollectionFileFormatRegistry()\n",
    "    outputFeatureCollection.write(vpgFeatureCollection, \"output/\" + str(gpmlOutputFile))\n",
    "\n",
    "# Check if new file was created and confirm export\n",
    "if os.path.isfile(\"output/\" + str(gpmlOutputFile)):\n",
    "    print \"Palaeomagnetic pole data successfully exported in GPML format\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
