{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pygplates as pgp\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File /Users/Mike/PhD/Palaeomagnetic_data/Torsvik_2012/publication_table/torsviketal2012_utf8.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b7258f419770>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load poles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpmag_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/Mike/PhD/Palaeomagnetic_data/Torsvik_2012/publication_table/torsviketal2012_utf8.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpmag_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpmag_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load polygon file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    644\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1388\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:4184)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:8449)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File /Users/Mike/PhD/Palaeomagnetic_data/Torsvik_2012/publication_table/torsviketal2012_utf8.csv does not exist"
     ]
    }
   ],
   "source": [
    "# Load poles\n",
    "pmag_file = '/Users/Mike/PhD/Palaeomagnetic_data/Torsvik_2012/publication_table/torsviketal2012_utf8.csv'\n",
    "pmag_data = pd.read_csv(pmag_file)\n",
    "\n",
    "# Load polygon file\n",
    "polyFile = '/Users/Mike/PhD/Plate_Models/Muller_etal_2016/Shapefiles/StaticPolygons/' + \\\n",
    "            'Global_EarthByte_GPlates_PresentDay_StaticPlatePolygons_2015_v1.gpml'\n",
    "\n",
    "#polyFile = '/Users/Mike/PhD/Plate_Models/Muller_etal_2016/Global_EarthByte_230-0Ma_GK07_AREPS_Coastlines.gpml'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pmag_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0c452a541a6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mblock_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterrane\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpmag_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTerrane\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mterrane\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterrane_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pmag_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Iterate through palaeomagnetic pole dataset (pmag_data) and build lists of unique terranes and continental blocks\n",
    "terrane_list = []\n",
    "block_list = []\n",
    "\n",
    "for i, terrane in enumerate(pmag_data.Terrane.values):\n",
    "    \n",
    "    if terrane not in terrane_list:\n",
    "        \n",
    "        terrane_list.append(pmag_data.Terrane[i])\n",
    "        \n",
    "        \n",
    "for j, block in enumerate(pmag_data.Block.values):\n",
    "    \n",
    "    if block not in block_list:\n",
    "        \n",
    "        block_list.append(pmag_data.Block[j])\n",
    "        \n",
    "#######\n",
    "\n",
    "# Iterate through palaeomagnetic pole data set and build Pandas DataFrame of required data\n",
    "pole_list = []\n",
    "\n",
    "for terrane in terrane_list:\n",
    "    \n",
    "    for k, item in enumerate(pmag_data.Terrane.values):\n",
    "        \n",
    "        if item == terrane:\n",
    "            \n",
    "            # Create dictionary for DataFrame\n",
    "            pole_list.append({'Terrane': pmag_data.Terrane[k], 'Block': pmag_data.Block[k], 'Formation': pmag_data.Formation[k], \n",
    "                              'PLat': pmag_data.PLat[k], 'PLon': pmag_data.PLon[k], 'CPlat': pmag_data.CLat[k],\n",
    "                              'CPlon':pmag_data.CLon[k], 'SLat': pmag_data.SLat[k],'SLon': pmag_data.SLon[k], \n",
    "                              'AgeNominal': pmag_data.AgeNominal[k], 'AgeLower': pmag_data.AgeLower[k], \n",
    "                              'AgeUpper': pmag_data.AgeUpper[k], 'A95': pmag_data.A95[k], 'N': pmag_data.N[k],\n",
    "                              'k': pmag_data.k[k], 'Dec': pmag_data.Dec[k], 'Inc': pmag_data.Inc[k], 'Q': pmag_data.Q[k]})\n",
    "            \n",
    "# Create and display Pandas DataFrame   \n",
    "raw_polesDF = pd.DataFrame(pole_list)\n",
    "print \"Number of poles:\", len(raw_polesDF)\n",
    "print \"\"\n",
    "raw_polesDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform 'point in polygon' test to assign plate ID to pole based on sampling location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featureCollection = pgp.FeatureCollectionFileFormatRegistry()\n",
    "featureSet = featureCollection.read(polyFile)\n",
    " \n",
    "try:\n",
    "    featureSet = featureCollection.read(polyFile)\n",
    "\n",
    "except pgp.OpenFileForReadingError:\n",
    "    print \"Doesn't work like that silly.\"\n",
    "\n",
    "\n",
    "plateIDs = []\n",
    "plates = []\n",
    "\n",
    "\n",
    "# Array to contain correct line numbers from full dataset to make sure the correct values are assiciated the correct poles.\n",
    "line = []\n",
    "count = 0\n",
    "polyCount = 0\n",
    "\n",
    "for i in xrange(0, len(raw_polesDF)):\n",
    "    \n",
    "    count = count + 1\n",
    "    \n",
    "    if pd.isnull(raw_polesDF.SLat[i]) == False:\n",
    "        inputlatLon = pgp.LatLonPoint(raw_polesDF.SLat[i], raw_polesDF.SLon[i])\n",
    "        latLonPoint = pgp.convert_lat_lon_point_to_point_on_sphere(inputlatLon)\n",
    "              \n",
    "    for feature in featureSet:\n",
    "        \n",
    "        for geometry in feature.get_geometries():\n",
    "            \n",
    "            polygon = pgp.PolygonOnSphere(geometry)\n",
    "            isPoly = polygon.is_point_in_polygon(latLonPoint)\n",
    "\n",
    "            if isPoly == True:\n",
    "\n",
    "                plateIDs.append(feature.get_reconstruction_plate_id())\n",
    "                plates.append(feature.get_name())\n",
    "                line.append(i)\n",
    "\n",
    "                # Uncomment this line for verbose output\n",
    "                # print \"Count: \" + str(count) + \", Line: \" + str(line[polyCount]) + \", Value: \" + str(raw_polesDF.a95[i]) + \\\n",
    "                # \", PlateID: \" + str(plateIDs[polyCount]) + \", Plate: \" + str(plates[polyCount])\n",
    "\n",
    "                polyCount = polyCount + 1\n",
    "\n",
    "print \"Polygon test complete. Located and assigned plate ID's to\", len(plateIDs), \"poles.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and populate FeatureCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loop through list of poles and produce GPML file of multiple VGPs.\n",
    "poleLat = []\n",
    "poleLon = []\n",
    "poleName = []\n",
    "poleInc = []\n",
    "poleDec = []\n",
    "poleSiteLat = []\n",
    "poleSiteLon = []\n",
    "poleNominalAge = []\n",
    "poleAgeLowerLimit = []\n",
    "poleAgeUpperLimit = []\n",
    "poleA95 = []\n",
    "plateID = []\n",
    "line = []\n",
    "\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in xrange(0, len(raw_polesDF)):\n",
    "    \n",
    "    line.append(i)\n",
    "    \n",
    "    if np.isfinite(raw_polesDF.PLat[i]) and np.isfinite(raw_polesDF.PLon[i]) and \\\n",
    "       np.isfinite(raw_polesDF.AgeLower[line[i]]) and np.isfinite(raw_polesDF.AgeUpper[line[i]]) and \\\n",
    "        np.isfinite(raw_polesDF.SLat[line[i]]) and np.isfinite(raw_polesDF.SLon[line[i]]) :\n",
    "            \n",
    "        # If poles have a CPlon or CPlat (inclination shallowing corrected pole) use that\n",
    "        if np.isfinite(raw_polesDF.CPlon[line[i]]) and np.isfinite(raw_polesDF.CPlat[line[i]]):\n",
    "\n",
    "            poleLat.append(raw_polesDF.CPlat[line[i]])\n",
    "            poleLon.append(raw_polesDF.CPlon[line[i]])\n",
    "\n",
    "        else:\n",
    "\n",
    "            poleLat.append(raw_polesDF.PLat[line[i]])\n",
    "            poleLon.append(raw_polesDF.PLon[line[i]])\n",
    "\n",
    "        poleName.append(raw_polesDF.Formation[line[i]])\n",
    "        poleInc.append(raw_polesDF.Inc[line[i]])\n",
    "        poleDec.append(raw_polesDF.Dec[line[i]])\n",
    "        poleSiteLat.append(raw_polesDF.SLat[line[i]])\n",
    "        poleSiteLon.append(raw_polesDF.SLon[line[i]])\n",
    "        poleNominalAge.append(raw_polesDF.AgeNominal[line[i]])\n",
    "        poleA95.append(raw_polesDF.A95[line[i]])\n",
    "        poleAgeLowerLimit.append(raw_polesDF.AgeLower[line[i]])\n",
    "        poleAgeUpperLimit.append(raw_polesDF.AgeUpper[line[i]])\n",
    "\n",
    "        plateID.append(plateIDs[line[i]])\n",
    "\n",
    "        count = count + 1\n",
    "    \n",
    "#Create new GPlates Feature Collection\n",
    "vpgFeatureCollection = pgp.FeatureCollection()\n",
    "    \n",
    "# Create new GPlates feature 'VirtualGeomagneticPole'.\n",
    "# Pole lat, pole lon, pole name, and reconstruction plate ID added within PointOnSphere method.\n",
    "# Inc, Dec, A95, Age and Sample site lat/lon values to added within 'other_properties' method.\n",
    "\n",
    "for j in xrange(0, count):\n",
    "\n",
    "    vgpFeature = pgp.Feature.create_reconstructable_feature(\n",
    "                 pgp.FeatureType.create_gpml('VirtualGeomagneticPole'),\n",
    "                 pgp.PointOnSphere([np.float(poleLat[j]), np.float(poleLon[j])]),\n",
    "                 name = poleName[j],\n",
    "                 reconstruction_plate_id = plateID[j],\n",
    "                 valid_time=(np.float(poleAgeUpperLimit[j]), np.float(poleAgeLowerLimit[j])),\n",
    "                 other_properties = [(pgp.PropertyName.create_gpml('averageInclination'), pgp.XsDouble(poleInc[j])),\n",
    "                                     (pgp.PropertyName.create_gpml('averageDeclination'), pgp.XsDouble(poleDec[j])),\n",
    "                                     (pgp.PropertyName.create_gpml('poleA95'), pgp.XsDouble(poleA95[j])),\n",
    "                                     (pgp.PropertyName.create_gpml('averageAge'), pgp.XsDouble(poleNominalAge[j])),\n",
    "                                     (pgp.PropertyName.create_gpml('averageSampleSitePosition'),\n",
    "                                      pgp.GmlPoint(pgp.PointOnSphere([np.float(poleSiteLat[j]), \n",
    "                                                                      np.float(poleSiteLon[j])])))])\n",
    "\n",
    "    # Add newly created feature to existing Feature Collection\n",
    "    vpgFeatureCollection.add(vgpFeature)\n",
    "    \n",
    "print str(len(poleLat)) + \" VGP Features created\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate GPML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate GPML output file\n",
    "gpmlOutputFile = \"All_PmagPoles_542-0Ma.gpml\"\n",
    "\n",
    "# Check for existing output directory and create it if not found\n",
    "if not os.path.exists(\"output\"):\n",
    "    os.makedirs(\"output\")\n",
    "\n",
    "# Check for existing output file with same name and remove if found\n",
    "if os.path.isfile(\"output/\" + str(gpmlOutputFile)):\n",
    "    os.remove(\"output/\" + str(gpmlOutputFile))\n",
    "\n",
    "# Check to make sure vgpFeatureCollection (feature collection) is not empty before writing to file\n",
    "if len(vpgFeatureCollection) != 0:\n",
    "    outputFeatureCollection = pgp.FeatureCollectionFileFormatRegistry()\n",
    "    outputFeatureCollection.write(vpgFeatureCollection, \"output/\" + str(gpmlOutputFile))\n",
    "\n",
    "# Check if new file was created and confirm export\n",
    "if os.path.isfile(\"output/\" + str(gpmlOutputFile)):\n",
    "    print \"Palaeomagnetic pole data successfully exported in GPML format\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
